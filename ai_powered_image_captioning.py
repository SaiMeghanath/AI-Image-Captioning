# -*- coding: utf-8 -*-
"""AI-Powered Image Captioning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KnUkbIULs0g4Hq5TTJQQgsUMs9r7yge7

**Step 1: Installing Dependencies**
"""

!pip install transformers pillow torch

"""**Step 2: Loading the Model**"""

from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import requests

# Load the model and processor
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

"""**Step 3: Define the Captioning Function**"""

def generate_caption(image_url):
    try:
        response = requests.get(image_url, stream=True)

        # Check if the response is valid
        if response.status_code != 200:
            return "Error: Unable to fetch the image. Check the URL."

        image = Image.open(response.raw).convert("RGB")  # Ensure correct format

        # Process the image
        inputs = processor(images=image, return_tensors="pt")

        # Generate caption
        out = model.generate(**inputs)
        caption = processor.decode(out[0], skip_special_tokens=True)

        return caption

    except Exception as e:
        return f"Error: {str(e)}"

"""** Step 4: Test with an Image**"""

image_url = "https://images.pexels.com/photos/1108099/pexels-photo-1108099.jpeg"
caption = generate_caption(image_url)
print("Generated Caption:", caption)